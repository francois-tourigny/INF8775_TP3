{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNG5DI3nlnIA"
   },
   "source": [
    "# INF8775 – Analyse et conception d’algorithmes\n",
    "# TP3 – Automne 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gobfFF2IlnIB"
   },
   "source": [
    "Côté, Gabriel, 2082508\n",
    "\n",
    "Tourigny, François, 2079718"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9CyGQLAlnIC"
   },
   "source": [
    "Note finale:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYmoxM0BlnIC"
   },
   "source": [
    "<u>**Date limite de remise :**</u>  4 décembre 23h59 pour les deux groupes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HEd-K_glnID"
   },
   "source": [
    "# Instructions\n",
    "\n",
    "## Rédaction et remise du rapport\n",
    "\n",
    "- Ce notebook constitue à la fois le sujet du TP, votre code et votre rapport. Il contient déjà du code pour faciliter vos mesures et l'affichage de vos résultats, ainsi qu'un squelette pour votre rapport.\n",
    "\n",
    "- Complétez directement le notebook, vous êtes libres de créer des nouvelles cellules de code ou de texte.\n",
    "\n",
    "- Vous pouvez utiliser des fichiers externes pour stocker des exemplaires et des résultats, mais nous devons être capable de comprendre facilement votre démarche et de la reproduire.\n",
    "\n",
    "- <u>**IMPORTANT**</u> Remettez le fichier du notebook sur Moodle avec le nom `MATRICULE1_MATRICULE2.ipynb`\n",
    "\n",
    "- Vous pouvez inclure du code trouvé sur Internet, mais vous devez en mentionner la source, sous peine d'être sanctionnés pour plagiat.\n",
    "\n",
    "## Mise en situation\n",
    "\n",
    "Ce travail pratique se répartit sur deux séances de laboratoire et est une occasion de mettre en application les connaissances vues en cours. Vous devrez développer l'algorithme de votre choix pour essayer de résoudre le plus efficacement possible le problème donné. Une partie de la note sera accordée en fonction des résultats que vous obtiendrez par rapport aux autres équipes.\n",
    "\n",
    "## Description du problème\n",
    "\n",
    "Le problème qu'on vous demande de résoudre cette fois-ci est un peu plus difficile. Vous êtes responsable de la séparation des voteurs d'un pays en circonscriptions. Un des deux candidats principaux, M. T, vient vous voir et vous demande de lui garantir une victoire (pour un montant non négligeable d'argent). Évidemment, vous refusez, mais le problème est intéressant et vous décidez d'essayez de le résoudre. Si ça vous intéresse, ce problème est ce qu'on appelle du *gerrymandering*.\n",
    "\n",
    "Vous aurez comme entrée à votre problème une carte du pays (représentée par une matrice carrée $n \\times n$) qui contient à chaque position le nombre de voteurs pour candidat X (un chiffre entre 0 et 1000). Votre objectif est de créer $n$ circonscriptions de sorte à ce que candidat X gagne l'élection. Quelques spécifications importantes:\n",
    "\n",
    "- La variable $n$ représente un côté de la matrice. Il y a donc, $n^2$ villes.\n",
    "- Chaque position de la matrice représente une ville\n",
    "- Chaque circonscription doit contenir **$n$ villes**. Une solution reste valide si une circonscription ne contient pas exactement $n$ villes, mais il y a une **pénalité** qui y est associée.\n",
    "- Les villes d'une circonscription doivent être proche les unes des autres. On aimerait garder cette **distance à, au plus, $n/2$**. Encore une fois, on permet de briser cette contrainte, mais il y aura une pénalité qui y est associée. (**Distance manhattan**)\n",
    "- Les villes d'une circonscription ne doivent **pas être nécessairement voisines** tant qu'on respecte la distance maximale. Voir l'exemple plus bas.\n",
    "- Le candidat remporte une circonscription si le nombre de voteurs dans cette circonscription est supérieur à $500n$.\n",
    "- Le candidat cherche à remporter le plus de circonscriptions qu'il peut.\n",
    "\n",
    "![alt text](distance_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqG5rRjSlnIE"
   },
   "source": [
    "\n",
    "## Jeu de données\n",
    "\n",
    "La classe Problem existe pour simplifier l'interface des différentes fonctions utilitaires. Elle permet de générer des jeux de données avec la méthode `generate_sample` ci-dessous. Elle génère une matrice carrée de taille $n$ contenant des nombres entre $1$ et $1000$. Vous pouvez utilisez des exemplaires aléatoires pour tester votre code. La compétition sera faite sur les mêmes exemplaires de tailles différentes pour toutes les équipes d'un même groupe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h9ZlrNOBlnIF"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections.abc import Iterable\n",
    "\n",
    "def generate_city() -> int:\n",
    "    return round(min(1000,max(0,random.normalvariate(450,200))))\n",
    "\n",
    "class Problem():\n",
    "    def __init__(self, size: int, num_samples: int = 5) -> None:\n",
    "        self.size = size\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def generate_sample(self) -> list[list[int]]:\n",
    "        \"\"\"Returns a matrix containing values between 0 and 1000. Each value is the number of voters in a given city\"\"\"\n",
    "        return [[generate_city() for _ in range(self.size)] for _ in range(self.size)]\n",
    "\n",
    "    def generate_dataset(self) -> Iterable[list[list[int]]]:\n",
    "        \"\"\"Returns an iterator over as many samples as are described\"\"\"\n",
    "        return (self.generate_sample() for _ in range(self.num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAvab0yKlnIG"
   },
   "source": [
    "# Implantations et expérimentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1U7ktXeVlnIG"
   },
   "source": [
    "Ces fonctions auxiliaires vous sont fournies pour vérifier l'exactitude des vos algorithmes, mesurer leurs performance et afficher vos résultats.\n",
    "\n",
    "Il est recommandé de prendre le temps de lire et comprendre le code.\n",
    "\n",
    "Exécutez la cellule ci-dessous pour pouvoir utiliser les fonctions auxiliaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7pWvysBtlnIH"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections.abc import Callable\n",
    "from math import ceil\n",
    "import math\n",
    "from scipy.stats import linregress\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "class InvalidSolution(Exception):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Invalid solution, verify your code.\")\n",
    "\n",
    "class Measure():\n",
    "    \"\"\"A wrapper to contain information on taken measures\"\"\"\n",
    "    def __init__(self, size: int, mean: int, score:int) -> None:\n",
    "        self.size = size\n",
    "        self.mean_score = score\n",
    "        self.mean = mean\n",
    "\n",
    "def score_solution(original: list[list[int]], solution: list[list[tuple[int,int]]]) -> int:\n",
    "    \"\"\"Returns the score of the current solution. The score function is a penalty that must be minimized.\"\"\"\n",
    "    return votes_score(original, solution) + size_score(solution) + distance_score(solution)\n",
    "\n",
    "def votes_score(original: list[list[int]], solution: list[list[tuple[int,int]]]) -> int:\n",
    "    \"\"\"Calculates the part of the score associated to lost districts. \n",
    "    It is 5 times the square of the number of lost districts.\"\"\"\n",
    "    lost_districts = 0\n",
    "    for district in solution:\n",
    "        sum = 0\n",
    "        for city in district:\n",
    "            sum += original[city[0]][city[1]]\n",
    "        if sum <= 500*len(district):\n",
    "            lost_districts += 1\n",
    "    return 5 * lost_districts**2\n",
    "\n",
    "def size_score(solution: list[list[tuple[int,int]]]) -> int:\n",
    "    \"\"\"Calculates the part of the score associated to districts having the wrong size.\n",
    "    It is the square of the difference between the wanted number of cities and the \n",
    "    current number of cities in a given district.\"\"\"\n",
    "    n = len(solution)\n",
    "    size_penality = 0\n",
    "    for district in solution:\n",
    "        size_penality += (len(district)-n)**2\n",
    "    return size_penality\n",
    "\n",
    "def distance_score(solution: list[list[tuple[int,int]]]) -> int:\n",
    "    \"\"\"Calculates the part of the score associated to the distance between cities in a district.\n",
    "    It is the mean square distance between each city and every other city in its district.\"\"\"\n",
    "    distance_score = 0\n",
    "    n = len(solution)\n",
    "    for district in solution:\n",
    "        for i,city in enumerate(district):\n",
    "            for j in range(i+1, len(district)):\n",
    "                distance_score += (max(0, distance_manhattan(city, district[j])-ceil(n/2)))**2\n",
    "    return distance_score/len(solution)\n",
    "\n",
    "def distance_manhattan(city_a: tuple[int,int], city_b: tuple[int,int]) -> int:\n",
    "    return abs(city_a[0] - city_b[0]) + abs(city_a[1] - city_b[1])\n",
    "\n",
    "def is_valid_solution(original: list[list[int]], solution: list[list[tuple[int,int]]]) -> bool:\n",
    "    \"\"\"Validates solution\"\"\"\n",
    "    n = len(original)\n",
    "\n",
    "    if len(solution) != n:\n",
    "        print(f\"The solution does not contain {n} districts.\")\n",
    "        return False\n",
    "\n",
    "    for district in solution:\n",
    "        if len(district) < 1:\n",
    "            print(\"The solution contains empty districts.\")\n",
    "            return False\n",
    "        for city in district:\n",
    "            if len(city)!=2:\n",
    "                print(\"Solution must contain 2 coordinates per city.\")\n",
    "                return False\n",
    "        for coord in city:\n",
    "            if coord < 0 or coord >=n:\n",
    "                print(f\"City coordinates must below {n} and positive.\")\n",
    "                return False\n",
    "\n",
    "    coord_set = set()\n",
    "    for district in solution:\n",
    "        for city in district:\n",
    "            coord_set.add(city)\n",
    "    if len(coord_set) != n*n:\n",
    "        print(f\"Solution contained {len(coord_set)} different cities while there should be {n*n} cities in the solution.\")\n",
    "        return False\n",
    "\n",
    "    # Solution is valid\n",
    "    return True\n",
    "\n",
    "def make_problems(sizes: list[int], num_samples: int = 5) -> list[Problem]:\n",
    "    \"\"\"Creates problem instances using given sizes and max_numbers\"\"\"\n",
    "    return [Problem(size,num_samples) for size in sizes]\n",
    "\n",
    "def measure(procedure: Callable[[list[list[int]]],list[list[tuple[int,int]]]], sample: list[list[int]], time_scale: int = 1000) -> tuple[int,int]:\n",
    "    \"\"\"Returns a tuple containing the time as well as the score of the solution, in that order.\n",
    "    \n",
    "    Parameters:\n",
    "        time_scale: Controls the level of precision of the time measurements.\n",
    "\n",
    "    Raises:\n",
    "        InvalidSolution: If the procedure returns an invalid solution, raises an exception.\n",
    "    \"\"\"\n",
    "    start: int = time.time() * time_scale\n",
    "    solution: list[int] = procedure(sample)\n",
    "    end: int = time.time() * time_scale\n",
    "    if not is_valid_solution(sample, solution):\n",
    "        raise InvalidSolution()\n",
    "    return (round(end - start), score_solution(sample, solution))\n",
    "\n",
    "def measure_mean(procedure: Callable[[list[list[int]]],list[list[tuple[int,int]]]], prob: Problem, time_scale: int = 1000) -> Measure:\n",
    "    \"\"\"Generates multiple samples with the specified parameters and returns a Measure \n",
    "    instance representing the result as well as the problem.\n",
    "\n",
    "    Raises:\n",
    "        InvalidSolution: If one of the samples results in an invalid solution.\n",
    "    \"\"\"\n",
    "    results = [measure(procedure,sample,time_scale) for sample in prob.generate_dataset()]\n",
    "    mean_time = sum(result[0] for result in results) / prob.num_samples\n",
    "    mean_score = sum(result[1] for result in results) / prob.num_samples\n",
    "    return Measure(prob.size, mean_time, mean_score)\n",
    "\n",
    "def measure_range(procedure: Callable[[list[list[int]]],list[list[tuple[int,int]]]], problems: list[Problem], time_scale: int = 1000) -> list[Measure]:\n",
    "    \"\"\"Measures the mean time taken for each problem in the given list.\n",
    "\n",
    "    Raises:\n",
    "        InvalidSolution: If one of the samples results in an invalid solution.\n",
    "\n",
    "    Returns:\n",
    "        A list of Measure instances containing the specifications\n",
    "        of the problem as well as the mean time and the score.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        measure_mean(procedure, prob, time_scale)\n",
    "        for prob in problems\n",
    "    ]\n",
    "\n",
    "def display_data_as_table(measures: list[Measure]):\n",
    "    \"\"\"Prints a table with the data in the given list of measures\"\"\"\n",
    "    print(\"{: <12} {: <12} {: <12}\".format(\"Taille\", \"Temps moyen\", \"Score moyen\"))\n",
    "    for measure in measures:\n",
    "        print(\"{: <12} {: <12} {: <12}\".format(measure.size, measure.mean, measure.mean_score))\n",
    "\n",
    "### The different tests are below, the names are in french to avoid confusion\n",
    "\n",
    "def test_de_puissance(\n",
    "    data: dict[int,int],\n",
    "    x_label: str,\n",
    "    y_label: str,\n",
    "    title: str = \"Test de puissance\"\n",
    "):\n",
    "    \"\"\"Takes the data and displays it into the corresponding test graph.\n",
    "    It applies no transformations to the data.\n",
    "\n",
    "    Args:\n",
    "        data (dict[int,int]): A dictionnary mapping the x variable to the y variable\n",
    "    \"\"\"\n",
    "    # Log both sets of values\n",
    "    x = list(data.keys())\n",
    "    y = list(data.values())\n",
    "\n",
    "    # Perform the lin regression\n",
    "    m, b, rvalue, _, _ = linregress(x, y)\n",
    "\n",
    "    # Estimate the values of y based on the lin regression results\n",
    "    predicted = [m * iter + b for iter in x]\n",
    "\n",
    "    # Create the line equation\n",
    "    line_eq = f\"y = {m:.2f}x + {b:.2f}\"\n",
    "\n",
    "    # Plot the points\n",
    "    plt.scatter(x, y, label='Mesures')\n",
    "\n",
    "    # Plot the regression line\n",
    "    plt.plot(x, predicted, color=\"red\", label=f'Regression linéaire R²={round(rvalue**2,6)}')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend(bbox_to_anchor=(0.60, 0), loc='lower left')\n",
    "\n",
    "    # Display the line equation\n",
    "    plt.text(min(x), max(y), line_eq)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "def test_de_rapport(\n",
    "    data: dict[int,int],\n",
    "    x_label: str,\n",
    "    y_label: str,\n",
    "    title: str = \"Test de rapport\"\n",
    "):\n",
    "    \"\"\"Takes the data and displays it into the corresponding test graph.\n",
    "    It applies no transformations to the data.\n",
    "\n",
    "    Args:\n",
    "        data (dict[int,int]): A dictionnary mapping the x variable to the y variable\n",
    "    \"\"\"\n",
    "    x = list(data.keys())\n",
    "    y = list(data.values())\n",
    "\n",
    "    plt.plot(x, y, label='Mesures')\n",
    "    plt.scatter(x, y, label='Mesures')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def test_de_constantes(\n",
    "    data: dict[int,int],\n",
    "    x_label: str,\n",
    "    y_label: str = \"Temps (ms)\",\n",
    "    title: str = \"Test de constantes\"\n",
    "):\n",
    "    \"\"\"Takes the data and displays it into the corresponding test graph.\n",
    "    It applies no transformations to the data.\n",
    "\n",
    "    Args:\n",
    "        data (dict[int,int]): A dictionnary mapping the x variable to the y variable\n",
    "    \"\"\"\n",
    "    x = list(data.keys())\n",
    "    y = list(data.values())\n",
    "\n",
    "    # Perform linear regression\n",
    "    m, b, rvalue, _, _ = linregress(x, y)\n",
    "\n",
    "    predicted = [m * iter + b for iter in x]\n",
    "\n",
    "    # Create the line equation\n",
    "    line_eq = f\"y = {m:.2E}x + {b:.2E}\"\n",
    "\n",
    "    # Plot the points\n",
    "    plt.scatter(x, y, label='Mesures')\n",
    "\n",
    "    # Plot the regression line\n",
    "    plt.plot(x, predicted, color=\"red\", label=f'Regression linéaire R²={round(rvalue**2,6)}')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend(bbox_to_anchor=(0.60, 0), loc='lower left')\n",
    "\n",
    "    # Display the line equation\n",
    "    plt.text(min(x), max(y), line_eq)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "telzEIacsEF6"
   },
   "source": [
    "# Algorithme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TXfOnFLuBG2"
   },
   "source": [
    "Votre algorithme sera en partie noté en fonction d'une évaluation relative entre les équipes. 4 points seront donnés aux équipes qui se classeront dans le premier quartile lors de notre évaluation sur un ensemble d'exemplaires. Les équipes se trouvant dans le quartile dont les algorithmes ont le moins bien performé recevront 1 point.\n",
    "\n",
    "**IMPORTANT** Votre algo doit retourner une solution après 3 minutes. Si ce n'est pas le cas, vous serez pénalisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class County():\n",
    "    def __init__(self, row: int, col: int, pos: int, voters: int) -> None:\n",
    "        self.row = row\n",
    "        self.col = col\n",
    "        self.pos = pos\n",
    "        self.voters = voters\n",
    "        self.neighbors = []\n",
    "        self.group = -1\n",
    "\n",
    "    def add_neighbor(self, neighbor):\n",
    "        self.neighbors.append(neighbor)\n",
    "\n",
    "    def get_neighbours(self):\n",
    "        return self.neighbors\n",
    "    \n",
    "    def set_group(self, group: int):\n",
    "        self.group = group\n",
    "    \n",
    "    def get_group(self):\n",
    "        return self.group\n",
    "    \n",
    "    def is_in_group(self):\n",
    "        return self.group != -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbours_idx(idx, n):\n",
    "    neighbours = []\n",
    "    if idx - n > 0:\n",
    "        neighbours.append(idx-n)\n",
    "    if idx + n < n**2:\n",
    "        neighbours.append(idx+n)\n",
    "    if idx // n == (idx-1) // n:\n",
    "        neighbours.append(idx-1)\n",
    "    if idx // n == (idx+1) // n:\n",
    "        neighbours.append(idx+1)\n",
    "    return neighbours\n",
    "\n",
    "def set_counties(sample) -> list[County]:\n",
    "    n = len(sample)\n",
    "    counties = [County(i, j, i*n+j, county) for i, line in enumerate(sample) for j, county in enumerate(line)]\n",
    "    for county in counties:\n",
    "        for neighbor_idx in get_neighbours_idx(county.pos, n):\n",
    "            county.add_neighbor(counties[neighbor_idx])\n",
    "    return counties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(county_row, county_col, center_row, center_col, n):\n",
    "    return (abs(center_row - county_row) + abs(center_col - county_col))\n",
    "    \n",
    "def max_to_target(counties: list[County], target: int, n: int):\n",
    "    solution = []\n",
    "    counties_available = counties\n",
    "    groups = []\n",
    "    groups_center = []\n",
    "    center_row = 0\n",
    "    center_col = 0\n",
    "    for group_id in trange(n):\n",
    "        new_group = []\n",
    "        number_items = 0\n",
    "        center_row = 0\n",
    "        center_col = 0\n",
    "        group_neighbors = []\n",
    "        while len(new_group) < n:\n",
    "            selection = None\n",
    "            if len(group_neighbors) == 0:\n",
    "                selection = max(counties_available, key=lambda county: county.voters/n - distance(county.row, county.col, center_row, center_col, n)**2/n)\n",
    "            elif sum(county.voters for county in new_group) < target:\n",
    "                selection = max(group_neighbors, key=lambda county: county.voters/n - distance(county.row, county.col, center_row, center_col, n)**2/n)\n",
    "                #selection = random.choice(group_neighbors)\n",
    "            else:\n",
    "                selection = min(group_neighbors, key=lambda county: county.voters/n + distance(county.row, county.col, center_row, center_col, n)**2/n)\n",
    "\n",
    "            new_group.append(selection)\n",
    "            center_row = (center_row * number_items + selection.row) / (number_items + 1)\n",
    "            center_col = (center_col * number_items + selection.col) / (number_items + 1)\n",
    "            number_items += 1\n",
    "            selection.set_group(group_id)\n",
    "            \n",
    "            group_neighbors.extend([neighbor for neighbor in selection.neighbors if not neighbor.is_in_group() and not neighbor in group_neighbors])\n",
    "            counties_available.remove(selection)\n",
    "            if selection in group_neighbors:\n",
    "                group_neighbors.remove(selection)\n",
    "            \n",
    "        groups.append(new_group)\n",
    "        groups_center.append((center_row, center_col))\n",
    "        solution.append([(county.row, county.col) for county in new_group])\n",
    "    return solution, groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(sample):\n",
    "    start_time = time.time()\n",
    "    max_time = 60 * 3 - 1\n",
    "    n = len(sample)\n",
    "    target = 500 * n\n",
    "    counties = set_counties(sample)\n",
    "    print('initial solution')\n",
    "    sol, groups = max_to_target(counties, target, n)\n",
    "    if (time.time() - start_time) > max_time:\n",
    "        return sol\n",
    "    print(\"--- %s seconds for solution baseline ---\" % (time.time() - start_time))\n",
    "\n",
    "    #print('vote score: ', votes_score(sample, sol))\n",
    "    #print('size score: ', size_score(sol))\n",
    "    #print('distance score: ', distance_score(sol))\n",
    "    #print('intial score: ',score_solution(sample, sol))\n",
    "    #drawmap_of_discrits(n, sol)\n",
    "    first_iter = True\n",
    "    iter_time = time.time()\n",
    "    time_to_iter = 0\n",
    "    print('improvement')\n",
    "    while(True):\n",
    "        updated = amelioration_locale(groups, target, n, sample, sol)\n",
    "        sol = updated\n",
    "\n",
    "        if (time.time() - start_time) > max_time - time_to_iter:\n",
    "            return sol\n",
    "        if(first_iter):\n",
    "            first_iter = False\n",
    "            time_to_iter = (time.time() - iter_time)\n",
    "\n",
    "    #print(\" ---------------- AFTER UPDATE -----------------\")\n",
    "    #print('vote score: ', votes_score(sample, sol))\n",
    "    #print('size score: ', size_score(sol))\n",
    "    #print('distance score: ', distance_score(sol))\n",
    "    #print('total score: ', score_solution(sample, sol))\n",
    "    #drawmap_of_discrits(n, sol)\n",
    "    return sol\n",
    "\n",
    "\n",
    "def amelioration_locale(divisions, target, n, sample, sol):\n",
    "    #init_score = score_solution(sample, sol)\n",
    "    div_votes = [sum(county.voters for county in div) for div in divisions]\n",
    "    groups_center = [(sum(county.row for county in div)/n, sum(county.col for county in div)/n) for div in divisions]\n",
    "\n",
    "    #selected_div_idx = div_votes.index(max(div for div in div_votes if div < target))\n",
    "    #selected_div_idx = divisions.index(random.choice([div for div in divisions if sum(county.voters for county in div) < target]))\n",
    "    selected_div_idx = divisions.index(random.choice(divisions))\n",
    "    #selected_div_idx = div_votes.index(min(div_votes))\n",
    "\n",
    "    selected_div = divisions[selected_div_idx]\n",
    "    center_swap_group_row = groups_center[selected_div_idx][0]\n",
    "    center_swap_group_col = groups_center[selected_div_idx][1]\n",
    "\n",
    "    modified_selected_div = [county.voters + distance(center_swap_group_row, center_swap_group_col, county.row, county.col, n) for county in selected_div]\n",
    "    county_to_swap_idx = modified_selected_div.index(min(modified_selected_div))\n",
    "    county_to_swap = divisions[selected_div_idx][county_to_swap_idx]\n",
    "    #print('county to swap: ', county_to_swap.pos)\n",
    "    differential_needed = target - county_to_swap.voters\n",
    "    distance_div_swap = distance(center_swap_group_row, center_swap_group_col, county_to_swap.row, county_to_swap.col, n)\n",
    "\n",
    "    swap_scores = {}\n",
    "    for div_idx in range(len(divisions)):\n",
    "        if div_idx == selected_div_idx:\n",
    "            continue\n",
    "\n",
    "        votes_to_spare = div_votes[div_idx] - target\n",
    "        if votes_to_spare <= 0:\n",
    "            votes_to_spare = target\n",
    "        \n",
    "        div_center_row = groups_center[div_idx][0]\n",
    "        div_center_col = groups_center[div_idx][1]\n",
    "        distance_div_swap_new_group = distance(div_center_row, div_center_col, county_to_swap.row, county_to_swap.col, n)\n",
    "\n",
    "        for county_idx, county in enumerate(divisions[div_idx]):\n",
    "            if county.voters - county_to_swap.voters > votes_to_spare:\n",
    "                continue\n",
    "            dist_county_curr_group = distance(div_center_row, div_center_col, county.row, county.col, n)\n",
    "            dist_county_swap_group = distance(center_swap_group_row, center_swap_group_col, county.row, county.col, n)\n",
    "            score_voters =  (county.voters/n - county_to_swap.voters/n) + (0 if county.voters - county_to_swap.voters < differential_needed else target)\n",
    "            score_distance = (dist_county_curr_group + distance_div_swap) - (dist_county_swap_group + distance_div_swap_new_group)\n",
    "            swap_scores[county.pos] = score_voters + n * score_distance\n",
    "\n",
    "    #print(swap_scores)\n",
    "    if len(swap_scores) == 0:\n",
    "        return sol\n",
    "    switch_county_pos = max(swap_scores, key=swap_scores.get)\n",
    "    if swap_scores[switch_county_pos] < 0:\n",
    "        return sol\n",
    "    #print(switch_county_pos)\n",
    "    switch_county_row = switch_county_pos // n\n",
    "    switch_county_col = switch_county_pos % n\n",
    "\n",
    "    div_switch_idx = -1\n",
    "    pos_pair_switch = (switch_county_row, switch_county_col)\n",
    "    for div_idx in range(len(divisions)):\n",
    "        if pos_pair_switch in sol[div_idx]:\n",
    "            div_switch_idx = div_idx\n",
    "    \n",
    "    #update solution\n",
    "    sol[div_switch_idx].remove(pos_pair_switch)\n",
    "    sol[div_switch_idx].append((county_to_swap.row, county_to_swap.col))\n",
    "\n",
    "    sol[selected_div_idx].append(pos_pair_switch)\n",
    "    sol[selected_div_idx].remove((county_to_swap.row, county_to_swap.col))\n",
    "\n",
    "    #update divisions\n",
    "    divisions[selected_div_idx].remove(county_to_swap)\n",
    "    pos_arr = [div.pos for div in divisions[div_switch_idx]]\n",
    "\n",
    "    idx_select = pos_arr.index(switch_county_pos)\n",
    "    switch = divisions[div_switch_idx][idx_select]\n",
    "    divisions[selected_div_idx].append(switch)\n",
    "\n",
    "    divisions[div_switch_idx].append(county_to_swap)\n",
    "    divisions[div_switch_idx].remove(switch)\n",
    "\n",
    "    #print('new score: ',score_solution(sample, sol))\n",
    "    #drawmap_of_discrits(n, sol)\n",
    "    return sol\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats = measure_range(main, make_problems([100], 1) )\n",
    "\n",
    "display_data_as_table(resultats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawmap_of_discrits(n, discrits: list[list[tuple[int,int]]]):\n",
    "    colors = [[0 for _ in range(n)] for _ in range(n)]\n",
    "    for i,district in enumerate(discrits):\n",
    "        for city in district:\n",
    "            colors[city[0]][city[1]] = i+1\n",
    "\n",
    "    plt.imshow(colors, cmap='tab20')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFVvMwGpt_Vu"
   },
   "source": [
    "# Analyse asymptotique\n",
    "\n",
    "Notre algorithme se sépare en 3 grande sections. La première d'entre elle est la création des objets County avoir leur voisinage. La seconde section est la génération d'une séparation initiale et la dernière partie est une amélioration locale.\n",
    "\n",
    "# Création des County\n",
    "Commençons par la création des County. La création se sépare en 2 phases, la première est de créer chaque County qui se fait en temps constant pour les n² éléments donc ceci nous donne theta(n²). La seconde étape de création est de passer par chacun des County créés et placer leur voisins qui sont au nombre maximal de 4 donc nous avons une complexité de theta(4*n²) qui est dans le même ordre de grandeur que theta(n²). Bref, la création des objets County se fait en theta(n² + n²) ce qui veut dire une complexité de theta(n²).\n",
    "\n",
    "# Séparation initiale\n",
    "La deuxième portion de notre algorithme est un algorithme glouton qui fait une répartion des County en n groupes. Dans chacun des n groupes, on fait n fois la recherche d'un prochain élément. Dans cette recherche de prochain élément, nous avons 2 choix qui sont de faire une rechreche parmis les voisins s'il y en a et sinon parmis tout les County qui ne sont pas déjà choisis dans un groupe. Dans le pire des cas, nous avons n² choix pour notre recherche de la valeur maximale. Bien que nous savons que la grande majorité des fois cette recherche est plutôt dans un ordre de grandeur n, le pire cas est n² donc nous mettons n² pour l'analyse théorique. Ce qui nous donne une complexité de theta(n\\*n\\*n²) ceci équivaut à une complexité de theta(n⁴).\n",
    "\n",
    "# Amélioration locale\n",
    "La dernière partie est une amélioration locale. L'amélioration se fait en plusieurs sections successives. La première de ces sections de l'amélioration locale est de calculer le centre du groupe nous avons n appels de la distance pour chacun des n groupes ce qui fait au total n² appels de la distance qui est un calcul en temps constant. Cette première partie de l'amélioration locale est donc en theta(n²\\*1) donc theta(n²).\n",
    "La seconde partie de l'amélioration locale est la sélection d'un County à échanger qui est en theta(n) pour le choix du groupe dans lequel prendre le County à échanger puis de theta(n) pour choisir le County parmis le groupe choisi. Ceci nous theta(n+n) donc theta(n) pour la sélection du County à échanger. Nous devons ensuite sélectionner le County avec lequel le premier chois sera échangé. Pour tous les County qui ne sont pas dans le groupe initial, nous générons un score de préférence pour faire l'échange avec le County choisi initialement. Ce calcul de score est en temps constant pour les au maximum n² County possibles pour faire un échange. Bref, le choix du second County pour l'échange se fait en theta(n²\\*1) ce qui donne theta(n²).\n",
    "Finalement, pour l'amélioration locale, nous avons l'échange des deux éléments qui se fait en temps constant theta(1).\n",
    "Notre section d'amélioration locale se fait donc avec la complexité suivante theta(n²+n²+1) ce qui nous donne theta(n²)\n",
    "La section d'amélioration locale est exécutée tant que du temps est disponible (avec une marge de sureté), mais ultimement le nombre d'exécutions peut être comme indépendant de n.\n",
    "\n",
    "# Algorithme complet\n",
    "Pour notre algorithme complet, nous pouvons additionner la complexité théorique de nos sections, car elle sont exécutées l'une à la suite de l'autre.\n",
    "Nous avons donc theta(n²+n⁴+n²) ce qui nous donne une complexitée finale de theta(n⁴)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2z6hz2LWt_w-"
   },
   "source": [
    "# Analyse hybride\n",
    "\n",
    "\n",
    "PAS faire le test de constante (pour deux variable et on a pas)\n",
    "Faire le test de puissance (faire en log log comme échelle) On devrait voir la valeur 4x\n",
    "On peut utiliser un test de rapport pour confirmer le test de puissance\n",
    "Faire le test de rapport en dernier si tout fonctionne\n",
    "\n",
    "\n",
    "Expliquer l'utilisation de chacun des graphiques, expliquer en quoi le graphique justifie la complexité et pourquoi ne pas utiliser certain graphiques.\n",
    "\n",
    "Effectuer une analyse hybride de votre algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On s'assure de générer toujours les mêmes problèmes pour pouvoir comparer les parties d'algorithme\n",
    "problems = make_problems([x for x in range(11, 61)], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithme greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isolation de la solution greedy\n",
    "\n",
    "Ici, on réécris notre algorithme sans l'amélioration locale, pour évaluer la complexité de notre solution initiale. Si on se souviens bien, notre hypothèse était une complexité d'au plus theta n^4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On réécris certaines fonctions pour pouvoir les évaluer individuellement sans contrainte de temps maximum\n",
    "\n",
    "def main_greedy(sample):\n",
    "    start_time = time.time()\n",
    "    n = len(sample)\n",
    "    target = 500 * n\n",
    "    counties = set_counties(sample)\n",
    "    print('initial solution')\n",
    "    sol, groups = max_to_target(counties, target, n)\n",
    "    print(\"--- %s seconds for solution baseline ---\" % (time.time() - start_time))\n",
    "    return sol\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Génération de moyennes\n",
    "\n",
    "Ici on génère les moyennes de temps et de score pour chaque grandeur de n. On calcule à partir de n = 11 pour éviter le plus possible les problèmes de temps moyen inconsistant quand notre n est très petit. Pour plus de stabilité, nous faisons 10 runs par grandeur de n, pour au total 50 valeurs de n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats_greedy = measure_range(main_greedy, problems)\n",
    "\n",
    "display_data_as_table(resultats_greedy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test de puissance\n",
    "\n",
    "Ici, on utilise un test de puissance car on penses que notre algorithme greedy nous donne une complexité de theta(n^4), alors on essaie de confirmer que c'est bien le cas en regardant la pente de notre tendance sur le graphique log-log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_from_measures(measures: list[Measure]) -> dict:\n",
    "    dict = {}\n",
    "    for measure in measures:\n",
    "        dict[np.log(measure.size)] = np.log(measure.mean)\n",
    "    return dict\n",
    "\n",
    "dict_greedy_sol = dict_from_measures(resultats_greedy)\n",
    "\n",
    "test_de_puissance(dict_greedy_sol, \"log de la grandeur de n\", 'temps log moyen pour trouver la solution (ms)', \"Test de puissance pour algorithme glouton\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut voir sur le test de puissance, notre échelle log-log pour nos données nous donne une complexité autour de theta n^2.8, ce qui était attendu, mais beaucoup mieux que notre hypothèse de départ. Nous pensions que c'était theta(n^4), mais en pratique notre algorithme greedy performe beaucoup mieux que nous le pensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test de rapport\n",
    "\n",
    "Ici, on fait un test de rapport pour vérifier tout de même si notre hypothèse de départ peut être sensée, même si on sait maintenant que notre vraie complexité pratique est plutôt theta(n^2.8). C'est le dernier test que l'on considère pour cette partie, car on a pas besoin de faire le test de constance étant donné que nous n'avons qu'une variable dans notre algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def change_to_predict(measures: list[Measure], hypothesis = lambda x: x) -> dict:\n",
    "    new_dict = {}\n",
    "    for key in measures:\n",
    "        new_dict[key.size] = key.mean/hypothesis(key.size)\n",
    "    return new_dict\n",
    "\n",
    "test_de_rapport(change_to_predict(resultats_greedy, lambda x: x**4), \"grandeur de n\", \"temps moyen pour trouver la solution divisé par n^4 (ms)\" , \"Test de rapport sur l'algorithme glouton\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir, on converge mais on se rapproche extrèmement de 0, ce qui indique qu'on surestime la valeur de notre complexité. C'est tout à fait normal vu qu'on vient de voir une valeur de theta(n^2.8) en pratique. Par contre, il est tout de même possible avec la différence de vitesse sur nos machines que la vraie complexité varie dépendamment de facteurs qu'on ne peut pas controller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy et Amélioration locale avec un seul passage\n",
    "\n",
    "Ici, on réécris notre algorithme avec amélioration locale, pour évaluer la complexité de notre solution finale. Si on se souviens bien, notre hypothèse était une complexité d'au plus theta n^4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main_amelioration(sample):\n",
    "    start_time = time.time()\n",
    "    max_time = 60 * 3 - 1\n",
    "    n = len(sample)\n",
    "    target = 500 * n\n",
    "    counties = set_counties(sample)\n",
    "    print('initial solution')\n",
    "    sol, groups = max_to_target(counties, target, n)\n",
    "    if (time.time() - start_time) > max_time:\n",
    "        return sol\n",
    "    print(\"--- %s seconds for solution baseline ---\" % (time.time() - start_time))\n",
    "\n",
    "    first_iter = True\n",
    "    iter_time = time.time()\n",
    "    time_to_iter = 0\n",
    "    updated = amelioration_locale(groups, target, n, sample, sol)\n",
    "    sol = updated\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Génération de moyennes\n",
    "\n",
    "Ici on génère les moyennes de la même façon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultats_am_locale = measure_range(main_amelioration, problems)\n",
    "\n",
    "display_data_as_table(resultats_am_locale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_am_locale = dict_from_measures(resultats_am_locale)\n",
    "\n",
    "test_de_puissance(dict_am_locale, \"nombre d'éléments dans la liste\", 'temps moyen de tri (ms)', \"Test de puissance Merge sort nombre d'éléments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_de_rapport(change_to_predict(resultats_am_locale, lambda x: x**4), \"rapport entre n log(n) et les augmentations de temps\", \"nombre d'items à balancer dans les deux listes combinées\" , \"Test de rapport sur l'algorithme glouton\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amélioration locale\n",
    "\n",
    "Ceci était un essaie qui ne fonctionne pas de calculer indépendamment l'amélioration locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main_preparation(sample):\n",
    "#     start_time = time.time()\n",
    "#     n = len(sample)\n",
    "#     target = 500 * n\n",
    "#     counties = set_counties(sample)\n",
    "#     sol, groups = max_to_target(counties, target, n)\n",
    "#     return (sol, groups, sample, n, target, counties)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problems = make_problems([x for x in range(11, 15)], 10)\n",
    "# resultats_initials = {\"solutions_initiales\": [],\n",
    "#                        \"groupes\": [],\n",
    "#                        \"samples\": [],\n",
    "#                        \"ns\": [],\n",
    "#                        \"targets\": [], \n",
    "#                        \"counties\": []}\n",
    "# for prob in problems:\n",
    "#     solutions_initiales, groupes, samples, ns, targets, counties = [], [], [], [], [], []\n",
    "#     sols = [main_preparation(sample) for sample in prob.generate_dataset()]\n",
    "#     for sol in sols:\n",
    "#         solutions_initiales.append(sol[0])\n",
    "#         groupes.append(sol[1])\n",
    "#         samples.append(sol[2])\n",
    "#         ns.append(sol[3])\n",
    "#         targets.append(sol[4])\n",
    "#         counties.append(sol[5])\n",
    "    \n",
    "#     resultats_initials[\"solutions_initiales\"].append(solutions_initiales)\n",
    "#     resultats_initials[\"groupes\"].append(groupes)\n",
    "#     resultats_initials[\"samples\"].append(samples)\n",
    "#     resultats_initials[\"ns\"].append(ns)\n",
    "#     resultats_initials[\"targets\"].append(targets)\n",
    "#     resultats_initials[\"counties\"].append(counties)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def main_amelioration(sample, resultats_initials):\n",
    "#     start_time = time.time()\n",
    "#     max_time = 60 * 3 - 1\n",
    "#     n = len(sample)\n",
    "#     target = resultats_initials\n",
    "#     counties = resultats_initials[\"counties\"]\n",
    "#     print('initial solution')\n",
    "#     sol, groups = max_to_target(counties, target, n)\n",
    "#     if (time.time() - start_time) > max_time:\n",
    "#         return sol\n",
    "#     print(\"--- %s seconds for solution baseline ---\" % (time.time() - start_time))\n",
    "\n",
    "#     first_iter = True\n",
    "#     iter_time = time.time()\n",
    "#     time_to_iter = 0\n",
    "#     print('improvement')\n",
    "#     while(True):\n",
    "#         updated = amelioration_locale(groups, target, n, sample, sol)\n",
    "#         sol = updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(resultats_initials[\"groupes\"])\n",
    "\n",
    "# resultats_am_locale = measure(lambda x: amelioration_locale(x[\"groupes\"][0][0], x[\"targets\"][0][0], x[\"ns\"][0][0], x[\"samples\"][0][0], x[\"solutions_initiales\"][0][0]), resultats_initials)\n",
    "\n",
    "# display_data_as_table(resultats_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def measure(procedure: Callable[[list[list[int]]],list[list[tuple[int,int]]]], sample: list[list[int]], time_scale: int = 1000) -> tuple[int,int]:\n",
    "#     \"\"\"Returns a tuple containing the time as well as the score of the solution, in that order.\n",
    "    \n",
    "#     Parameters:\n",
    "#         time_scale: Controls the level of precision of the time measurements.\n",
    "\n",
    "#     Raises:\n",
    "#         InvalidSolution: If the procedure returns an invalid solution, raises an exception.\n",
    "#     \"\"\"\n",
    "#     start: int = time.time() * time_scale\n",
    "#     solution: list[int] = procedure(sample)\n",
    "#     end: int = time.time() * time_scale\n",
    "#     if not is_valid_solution(sample, solution):\n",
    "#         raise InvalidSolution()\n",
    "#     return (round(end - start), score_solution(sample, solution))\n",
    "\n",
    "# def measure_mean(procedure: Callable[[list[list[int]]],list[list[tuple[int,int]]]], prob: Problem, greedy_results, time_scale: int = 1000) -> Measure:\n",
    "#     \"\"\"Generates multiple samples with the specified parameters and returns a Measure \n",
    "#     instance representing the result as well as the problem.\n",
    "\n",
    "#     Raises:\n",
    "#         InvalidSolution: If one of the samples results in an invalid solution.\n",
    "#     \"\"\"\n",
    "#     results = [measure(procedure,sample,time_scale) for sample in prob.generate_dataset()]\n",
    "#     mean_time = sum(result[0] for result in results) / prob.num_samples\n",
    "#     mean_score = sum(result[1] for result in results) / prob.num_samples\n",
    "#     return Measure(prob.size, mean_time, mean_score)\n",
    "\n",
    "# def measure_range(procedure: Callable[[list[list[int]]],list[list[tuple[int,int]]]], problems: list[Problem], time_scale: int = 1000) -> list[Measure]:\n",
    "#     \"\"\"Measures the mean time taken for each problem in the given list.\n",
    "\n",
    "#     Raises:\n",
    "#         InvalidSolution: If one of the samples results in an invalid solution.\n",
    "\n",
    "#     Returns:\n",
    "#         A list of Measure instances containing the specifications\n",
    "#         of the problem as well as the mean time and the score.\n",
    "#     \"\"\"\n",
    "#     return [\n",
    "#         measure_mean(procedure, problems[i], resultats_initials[], time_scale)\n",
    "#         for i in len(problems)\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons essayé de faire l'analyse de la fonction d'amélioration locale indépendemment de l'algorithme principal. Par contre, comme l'amélioration locale demande une solution initiale sur laquelle faire l'amélioration et les fonctions fournies ne nous permettent pas isoler cette section de l'analyse. Par contre, nous avons fais l'analyse de la section de génération initale et aussi l'analyse de la génération initiale avec un passage d'amélioration locale. Nous voyons entre les deux analyse qu'il n'y a aucune différence d'ordre de grandeur. Ceci peux seulement nous borner supérieurement la complexité de notre amélioration locale qui est au pire dans le même ordre que la génération initiale. Nous savons que c'est O(n⁴) héoriquement et en pratique plus près de O(n³). Bref, un passage d'amélioration locale n'affecte pas l'ordre de grandeur, car il est au maximum aussi grand que nous génération de solution initiale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AB43Z14ssDna"
   },
   "source": [
    "# Analyse code carbon (2 pts)\n",
    "\n",
    "Effectuer une anlayse code carbon en sélectionnant différent pays pour l'analyse. Commenter vos résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codecarbon import EmissionsTracker, OfflineEmissionsTracker\n",
    "try:\n",
    "    tracker_USA = OfflineEmissionsTracker(measure_power_secs=5, tracking_mode=\"process\", country_iso_code='USA')\n",
    "    # tracker_CAD = OfflineEmissionsTracker(measure_power_secs=5, country_iso_code='CAN')\n",
    "    # tracker_JPN = OfflineEmissionsTracker(measure_power_secs=5, country_iso_code='JPN')\n",
    "    # tracker_FRA = OfflineEmissionsTracker(measure_power_secs=5, country_iso_code='FRA')\n",
    "    # tracker_CHN = OfflineEmissionsTracker(measure_power_secs=5, country_iso_code='CHN')\n",
    "\n",
    "    tracker_USA.start_task(\"main_USA\")\n",
    "    # tracker_CAD.start_task(\"main_CAD\")\n",
    "    # tracker_JPN.start_task(\"main_JPN\")\n",
    "    # tracker_FRA.start_task(\"main_FRA\")\n",
    "    # tracker_CHN.start_task(\"main_CHN\")\n",
    "\n",
    "    results = measure_range(main, make_problems([100], 1) )\n",
    "    tracker_USA.stop_task()\n",
    "    # tracker_CAD.stop_task()\n",
    "    # tracker_JPN.stop_task()\n",
    "    # tracker_FRA.stop_task()\n",
    "    # tracker_CHN.stop_task()\n",
    "\n",
    "finally:\n",
    "    _ = tracker_USA.stop()\n",
    "    # _ = tracker_CAD.stop()\n",
    "    # _ = tracker_JPN.stop()\n",
    "    # _ = tracker_FRA.stop()\n",
    "    # _ = tracker_CHN.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4Xx4XnglnII"
   },
   "source": [
    "# Conclusion (6 pts)\n",
    "\n",
    "# Étapes d'amélioration pour arriver à notre version actuelle\n",
    "Nous avons commencé par un algorithme glouton qui n'avait aucune gestion du temps et aucune amélioration après le passage initial. Cet algorithme était en theta(n³) au lieu de theta(n⁴) comme notre algorithme actuel, car nous faisions une selection  du premier élément d'un groupe de manière complètment aléatoire. De plus, lorsqu'il n'y avait pas de voisins disponibles pour choisir le prochain élément, l'élément choisi dans le groupe était aléatoire ce qui donnait de mauvais scores de distance. De plus, nous n'avions pas encore l'objet County pour nous aider à clarifier le code. Du fait, nos heuristiques de choix de prochain élément étaient très rudimentaires et inefficace. Les score pour n=100 étaient autour de 700 000.\n",
    "\n",
    "Nous avons par la suite ajouté une section d'amélioration locale. Pour choisir le groupe auquel nous voulions faire une amélioration, nous avons commencé par prendre celui qui a un nombre de vote le plus près d'une majorité et prendre le meilleur des échanges. Par contre, nous avons réalisé que certains des échanges étaient considérés comme sous optimaux et pris quand même. De plus, seulement un groupe recevait des modifications constantes jusqu'à atteindre un nombre de vote majoritaire puis un prochain. Nous avons donc changé notre algorithme pour prendre un groupe aléatoire parmis tous et vérifier que le meilleur échange améliore la situation et sinon ne pas faire d'échange. Ceci nous a permis de ne pas rester pris dans un minimum et presque toujours faire des améliorations avec chaque passage et arrêter seuelement lorsque le score obtenu est excellent.\n",
    "\n",
    "# Points forts de notre algorithme\n",
    "Notre algorithme trouve une solution initiale qui est souvent vraiment bonne et satisfaisante, même sans la mise en place d'une amélioration locale. Bref, bien que la complexité soit grande, notre passage initial donne une solution d'environ 25 000 pour n=100.\n",
    "\n",
    "L'autre force de notre algorithme est que l'amélioration locale améliore rellement le score même après une grande quantité d'améliorations. En effet, le groupe qui reçoit une amélioration est choisi aléatoirement ce qui nous permet de tout améliorer. De plus, si jamais la quantité d'amélioration maximale pour la solution actuelle est atteinte, notre algorithme va préférer ne prendre aucune action plutôt qu'une action sous optimale.\n",
    "\n",
    "# Points faibles de notre algorithme\n",
    "Notre algorithme est vraiment lent pour trouver une solution initiale. Bien que la solution soit bonne, elle demande un trop grand temps de calcul pour de grandes valeurs de n. Un autre point faible de notre algorithme est de ne pas prendre avantage du débalancement possible dans les grandeurs des groupes de County. Nous pourrions surement aller chercher des scores plus élevés avec un débalancement faible dans le nombre de County inclus par groupe.\n",
    "\n",
    "# Amélioration possibles\n",
    "Pour améliorer notre algorithme, 2 avenues sont à explorer. La première est de fournir une version encore plus rapide de solution initiale pour être correct dans des situations ou le n prend une très très grande valeur. Ainsi je crois qu'il faudrait un système de thread pour faire des interruptions pour s'assurer de ne pas dépasser les temps prévus peu import la technique utilisée. Bien sur, l'utilisation de thread serait aussi très utile pour accélérer les performances et non seulement faire un meilleur timer.\n",
    "\n",
    "La deuxième amélioration que nous aurions aimé explorer avec plus de temps est d'introduire un débalancement dans le nombre de County par groupe de vote. Ainsi, nous aurions pu réduire le score de groupes gagnés qui devient important avec des grandes valeurs par sa nature quadratique. Pour faire ce débalancement, l'algorithme d'amélioration locale pourrait avoir la capacité de prendre un County au lieu de simplement faire des échanges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCj6aXxQlnII"
   },
   "source": [
    " ## Autres critères (2 pts)\n",
    " Qualité du code / 1 pt\n",
    "\n",
    "Présentation générale / 1 pt\n",
    "\n",
    "- Concision\n",
    "- Qualité du français\n",
    "\n",
    "Pénalité retard\n",
    "- -2 pt / journée de retard, arrondi vers le haut. Les TPs ne sont plus acceptés après 3 jours."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "INF8775",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
